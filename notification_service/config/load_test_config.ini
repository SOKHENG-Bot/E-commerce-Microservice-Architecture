# Load Testing Configuration for User Service
# This file defines various load testing scenarios and thresholds

[general]
# Base URL for the service under test
base_url = http://localhost:8011

# Default test parameters
default_users = 50
default_spawn_rate = 5
default_run_time = 2m

# Performance thresholds (in milliseconds)
response_time_threshold_p50 = 500    # 50th percentile
response_time_threshold_p95 = 2000   # 95th percentile
response_time_threshold_p99 = 5000   # 99th percentile

# Error rate thresholds
max_error_rate_percent = 5.0

# Throughput expectations (requests per second)
expected_rps_light = 10
expected_rps_medium = 50
expected_rps_heavy = 200

[scenarios]

# Smoke Test - Basic functionality verification
[scenarios.smoke]
name = "Smoke Test"
description = "Basic functionality test with minimal load"
users = 5
spawn_rate = 1
run_time = 10s
expected_response_time = 200
expected_error_rate = 0.0

# Light Load Test - Normal usage simulation
[scenarios.light]
name = "Light Load Test"
description = "Simulates normal application usage"
users = 20
spawn_rate = 5
run_time = 1m
expected_response_time = 300
expected_error_rate = 1.0

# Medium Load Test - Busy period simulation
[scenarios.medium]
name = "Medium Load Test"
description = "Simulates busy periods with moderate load"
users = 100
spawn_rate = 10
run_time = 2m
expected_response_time = 500
expected_error_rate = 2.0

# Heavy Load Test - Stress testing
[scenarios.heavy]
name = "Heavy Load Test"
description = "Stress test for peak load scenarios"
users = 500
spawn_rate = 25
run_time = 3m
expected_response_time = 1000
expected_error_rate = 5.0

# Spike Test - Sudden traffic bursts
[scenarios.spike]
name = "Spike Test"
description = "Tests sudden increases in traffic"
users = 1000
spawn_rate = 50
run_time = 1m
expected_response_time = 2000
expected_error_rate = 10.0

# Benchmark scenarios for specific operations
[scenarios.auth_benchmark]
name = "Authentication Benchmark"
description = "Focused testing of auth operations"
users = 200
spawn_rate = 20
run_time = 5m
tags = login,registration
expected_response_time = 400

[scenarios.profile_benchmark]
name = "Profile Operations Benchmark"
description = "Testing profile CRUD operations"
users = 150
spawn_rate = 15
run_time = 5m
tags = profile,profile_update
expected_response_time = 600

[scenarios.health_benchmark]
name = "Health Check Benchmark"
description = "High-frequency health check testing"
users = 500
spawn_rate = 50
run_time = 3m
tags = health_check
expected_response_time = 100

[scenarios.read_heavy]
name = "Read-Heavy Scenario"
description = "Simulates read-heavy workloads"
users = 300
spawn_rate = 30
run_time = 4m
tags = get_me,health_check
expected_response_time = 200

[scenarios.write_heavy]
name = "Write-Heavy Scenario"
description = "Simulates write-heavy workloads"
users = 100
spawn_rate = 10
run_time = 4m
tags = registration,profile_update
expected_response_time = 800

[monitoring]
# System resource monitoring
enable_system_monitoring = true
monitor_interval_seconds = 5
monitor_duration_seconds = 300

# Database monitoring
enable_db_monitoring = true
db_host = localhost
db_port = 5432
db_name = user_service

# Application metrics
enable_app_metrics = true
metrics_endpoint = /user-service/metrics

[reporting]
# Report generation settings
generate_html_report = true
generate_csv_report = true
generate_summary_report = true

# Alert thresholds
alert_on_high_response_time = true
alert_on_high_error_rate = true
alert_on_app_downtime = true

[environment]
# Environment-specific settings
test_environment = development
enable_debug_logging = true
save_request_logs = true

# Database settings for tests
test_database_url = sqlite:///test_load.db
cleanup_after_test = true